{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA PREP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv(\"/Users/aniketsingh/SeniorProject/site_weather.csv\")\n",
    "#Making a list of missing values types\n",
    "missingValues = [\"n/a\", \"na\", \" \", \"__\"]\n",
    "data = pd.read_csv(\"/Users/aniketsingh/Desktop/SeniorProject/data/site_weather.csv\",na_values = missingValues)\n",
    "\n",
    "data.rename(columns = {'Unnamed: 0': 'Timestamp'}, inplace = True)\n",
    "data['Timestamp'] = pd.to_datetime(data['Timestamp'])\n",
    "data.set_index('Timestamp', inplace=True)\n",
    "\n",
    "#First few rows\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Total missing values for each feature \n",
    "print(\"-------------Here are the missing values----------\")\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------- Removing Missing Values-----#\n",
    "\n",
    "data = data.dropna()\n",
    "print(\"-------------Here are the missing values----------\")\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------- Normalized-------#\n",
    "scaler = MinMaxScaler()\n",
    "data_norm = data.copy()\n",
    "data_norm[:] = scaler.fit_transform(data_norm)\n",
    "data_norm.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_outlier(data, rolling_median, thresh):\n",
    "    if not pd.isna(rolling_median):\n",
    "        return abs(data - rolling_median) >= thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_nrm5 = data_norm.rolling(5, center=True).median()\n",
    "data_nc = data_norm.copy()\n",
    "s = data_nc.shape\n",
    "for j in range(s[1]):\n",
    "    for i in range(s[0]):\n",
    "        if is_outlier(data_nc.iloc[i, j], data_nrm5.iloc[i, j], 0.2):\n",
    "            data_nc.iloc[i, j] = data_nrm5.iloc[i, j]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction and Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ts_to_features(ts, n_features=48):\n",
    "    X, y = np.zeros([len(ts) - n_features, n_features]), np.zeros([len(ts) - n_features, 1])\n",
    "    for i in range(len(ts)-n_features):\n",
    "        X[i, :] = ts[i:i+n_features]\n",
    "        y[i] = ts[i+n_features]\n",
    "    return X, y.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ts_predict(X, y):\n",
    "    lower_alpha = 0.1\n",
    "    upper_alpha = 0.9\n",
    "    predictions = np.ones([1, 4])\n",
    "    for i in tqdm(range(1, X.shape[0])):\n",
    "        lower_model = GradientBoostingRegressor(loss=\"quantile\",                   \n",
    "                                        alpha=lower_alpha)\n",
    "        mid_model = GradientBoostingRegressor(loss=\"ls\")\n",
    "        upper_model = GradientBoostingRegressor(loss=\"quantile\",\n",
    "                                                alpha=upper_alpha)\n",
    "        lower_model.fit(X[:i,:], y[:i])\n",
    "        mid_model.fit(X[:i,:], y[:i])\n",
    "        upper_model.fit(X[:i,:], y[:i])\n",
    "        \n",
    "        pred = np.hstack([y[i], \n",
    "                          lower_model.predict(X[i:i+1, :]),\n",
    "                          mid_model.predict(X[i:i+1, :]),\n",
    "                          upper_model.predict(X[i:i+1, :])])\n",
    "        predictions = np.vstack([predictions, pred])\n",
    "    return predictions[1:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = data_nc.iloc[:, 0].values\n",
    "h = h[range(0, len(h), 48)]\n",
    "X, y = ts_to_features(h, 5)\n",
    "p = ts_predict(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = pd.DataFrame(p)\n",
    "p.columns = ['actual', 'lower', 'mid', 'upper']\n",
    "p['label'] = np.ones(len(p))\n",
    "for i in range(len(p)):\n",
    "    if p['actual'].iloc[i] > p['upper'].iloc[i]:\n",
    "        p['label'].iloc[i] = 2\n",
    "    if p['actual'].iloc[i] < p['lower'].iloc[i]:\n",
    "        p['label'].iloc[i] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot two scatter plots, showing the prediction interval and labels\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, sharex=True, figsize=(16, 10))\n",
    "ax1.scatter(p.index, p['actual'], color='tab:blue', alpha=1, label='Hourly Data')\n",
    "ax1.fill_between(p.index, p['upper'], p['lower'], color='tab:green', alpha=0.5, label='Prediction Interval')\n",
    "ax1.set_ylabel('Normalized Value')\n",
    "ax1.legend()\n",
    "ax1.set_title('Ozone - Low Conc.')\n",
    "ax2.plot(p['actual'], color='black', alpha=0.2)\n",
    "scatter = ax2.scatter(p.index, p['actual'], c=p['label'], cmap=plt.get_cmap('coolwarm'), alpha=0.8)\n",
    "ax2.set_xlabel('Hour')\n",
    "ax2.set_ylabel('Normalized Value')\n",
    "ax2.legend(handles=scatter.legend_elements()[0], labels=['Unexpected Decrease', 'Normal', 'Unexpected Increase'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "language": "python",
   "name": "python38564bitee6ad5eec1f648eb9c83d336c40eaec2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
